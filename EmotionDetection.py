# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LNE5o-LzFT9CLm3utx9znA_LA6Tkg91c

# New Section
"""

def emotionDetector(file):
  # from google.colab import drive
  # drive.mount('/content/drive')
  import sys
  sys.path.append('/content/drive/My Drive/OpenVokaturi-4-0/api')
  import Vokaturi
  import platform
  import struct
  import scipy.io.wavfile

  if platform.system() == "Darwin":
    assert struct.calcsize ("P") == 8
    Vokaturi.load("/content/drive/My Drive/OpenVokaturi-4-0/lib/open/macos/OpenVokaturi-4-0-mac.dylib")
  elif platform.system() == "Windows":
    if struct.calcsize ("P") == 4:
        Vokaturi.load("/content/drive/My Drive/OpenVokaturi-4-0/lib/open/win/OpenVokaturi-4-0-win32.dll")
    else:
        assert struct.calcsize ("P") == 8
        Vokaturi.load("l/content/drive/My Drive/OpenVokaturi-4-0/lib/open/win/OpenVokaturi-4-0-win64.dll")
  elif platform.system() == "Linux":
    assert struct.calcsize ("P") == 8
    Vokaturi.load("/content/drive/My Drive/OpenVokaturi-4-0/lib/open/linux/OpenVokaturi-4-0-linux.so")
  # print ("Analyzed by: %s" % Vokaturi.versionAndLicense())

  # print("Reading sound file...")
  # file_name = '/content/drive/My Drive/angry_voice.wav'
  # file_name=filename
  (sample_rate, samples) = scipy.io.wavfile.read(file)
  # print("   sample rate %.3f Hz" % sample_rate)

  # print("Allocating Vokaturi sample array...")
  buffer_length = len(samples)
  # print("   %d samples, %d channels" % (buffer_length, samples.ndim))
  c_buffer = Vokaturi.float64array(buffer_length)
  if samples.ndim == 1:
    c_buffer[:] = samples[:] / 32768.0  # mono
  else:
    c_buffer[:] = 0.5*(samples[:,0]+0.0+samples[:,1]) / 32768.0  # stereo

  # print("Creating VokaturiVoice...")
  voice = Vokaturi.Voice(sample_rate, buffer_length, 0)

  # print("Filling VokaturiVoice with samples...")
  voice.fill_float64array(buffer_length, c_buffer)

  # print("Extracting emotions from VokaturiVoice...")
  quality = Vokaturi.Quality()
  emotionProbabilities = Vokaturi.EmotionProbabilities()
  voice.extract(quality, emotionProbabilities)

  flag=0
  if quality.valid:
    flag=1
  else:
    flag=0
    print ("Not enough sonorancy to determine emotions")

  voice.destroy()
  if flag==1:
    emotions={}
    emotions['neutral']=emotionProbabilities.neutrality
    emotions['happy']=emotionProbabilities.happiness
    emotions['sad']=emotionProbabilities.sadness
    emotions['angry']=emotionProbabilities.anger
    emotions['fear']=emotionProbabilities.fear

    max=0
    count=0
    for i in emotions.values():
      if i>max:
        max=i
        count=count+1

    max=round(max,2)
    return list(emotions.keys())[count]
  else:
    return 'Unable to detect, Please try again'

!pip install flask-ngrok
!pip install pyngrok==4.1.1
!ngrok authtoken 2YVj4lJ84UIOa2TD6lbzqZfSdm9_4Sjp8PRYMYuy71r3wingS

# !pip install flask_ngrok
# !pip install pyngrok
# !ngrok authtoken 2YVj4lJ84UIOa2TD6lbzqZfSdm9_4Sjp8PRYMYuy71r3wingS
import os
from flask_ngrok import run_with_ngrok
from flask import request, jsonify, Flask
import random as r
import json
app = Flask(__name__)
run_with_ngrok(app)

# 2YVj4lJ84UIOa2TD6lbzqZfSdm9_4Sjp8PRYMYuy71r3wingS api key for ngrok

@app.route('/test',methods = ['POST', 'GET'])
def home():
  file = request.files.get('files').read()
  # print('---',file)
  if os.path.isfile('/content/drive/My Drive/rec.wav'):
    os.remove('/content/drive/My Drive/rec.wav')
  with open('/content/drive/My Drive/rec.wav', 'bx') as f:
    f.write(file)

  !ffmpeg -i '/content/drive/My Drive/rec.wav' -y output.wav
  file_name = 'output.wav'
  return emotionDetector(file_name)

app.run()

